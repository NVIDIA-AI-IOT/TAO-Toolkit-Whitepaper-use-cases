{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "581ab908",
   "metadata": {},
   "source": [
    "## Process and Run Experiment on the Helmet Dataset\n",
    "\n",
    "This notebook contains all code needed to train use Peoplenet to inference a dataset and then train with an added class\n",
    "\n",
    "This notebook is required to run in the TLT Stream Analysytics container which can be found here. \n",
    "https://ngc.nvidia.com/catalog/containers/nvidia:tlt-streamanalytics\n",
    "\n",
    "The github readme has steps on how pull and launch the container. \n",
    "\n",
    "The notebook also requires a helmet dataset from kaggle which can be found here https://www.kaggle.com/andrewmvd/helmet-detection\n",
    "\n",
    "It must be downloaded the archive.zip placed in /datasets/helmet\n",
    "\n",
    "This notebook takes the following steps\n",
    "\n",
    "1) Clear past results\n",
    "2) Convert the dataset into kitti format\n",
    "3) Download PeopleNet model\n",
    "4) Inference the images with PeopleNet and combine labels\n",
    "5) Generate TF Records\n",
    "6) Train PeopleNet with the helmet class\n",
    "7) Graph Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34ee447",
   "metadata": {},
   "source": [
    "### Clear past results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ceb82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r /datasets/helmet_set_all\n",
    "!rm -r /datasets/annotations\n",
    "!rm -r /datasets/images\n",
    "!rm -r /datasets/peoplenet_labels\n",
    "!rm -r /tlt_exp/peoplenet_helmet/experiments/trained_inf_out\n",
    "!rm -r /tlt_exp/peoplenet_helmet/experiments/train_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9545355f",
   "metadata": {},
   "source": [
    "### Convert the dataset into kitti format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39870ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_home = \"/datasets/helmet\"\n",
    "exp_home = \"/tlt_exp/peoplenet_helmet/experiments\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb0fb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /datasets/helmet\n",
    "!unzip /datasets/helmet/archive.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc974202",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess_helmet import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a284e0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_out = os.path.join(dataset_home, \"helmet_set_all/labels\")\n",
    "image_out = os.path.join(dataset_home, \"helmet_set_all/images\")\n",
    "\n",
    "os.makedirs(image_out, exist_ok=True)\n",
    "os.makedirs(label_out, exist_ok=True)\n",
    "\n",
    "!mv /datasets/helmet/images/* $image_out\n",
    "\n",
    "xml_labels = os.path.join(dataset_home, \"annotations\")\n",
    "for label in os.listdir(xml_labels):\n",
    "    convert_annotation(os.path.join(xml_labels,label), label_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b090b3c",
   "metadata": {},
   "source": [
    "### Download PeopleNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7be5132",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"/tlt_exp/models/detectnet_v2\", exist_ok=True)\n",
    "%cd /tlt_exp/models/detectnet_v2\n",
    "!ngc registry model download-version \"nvidia/tlt_peoplenet:unpruned_v2.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5292cd4f",
   "metadata": {},
   "source": [
    "### Inference the images with PeopleNet and combine labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fffcac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_spec = os.path.join(exp_home,\"inf_people_spec.txt\")\n",
    "output_folder = os.path.join(dataset_home, \"peoplenet_labels\")\n",
    "dataset_images = os.path.join(dataset_home, \"helmet_set_all/images\")\n",
    "key = \"tlt_encode\"\n",
    "\n",
    "!detectnet_v2 inference -e $inference_spec -o $output_folder -i $dataset_images -k $key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851c50f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in os.listdir(os.path.join(dataset_home,\"helmet_set_all/labels\")):\n",
    "    helmet_label = os.path.join(dataset_home, \"helmet_set_all/labels\", label)\n",
    "    inferenced_labels = os.path.join(output_folder, \"labels\")\n",
    "    people_label = os.path.join(output_folder,\"labels\",label)\n",
    "    with open(helmet_label, \"a\") as label_f:\n",
    "        with open(people_label, \"r\") as people_f:\n",
    "            for line in people_f:\n",
    "                line = line.split(\" \")\n",
    "                line = \" \".join(line[:-1])\n",
    "                label_f.write(line + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d68ef01",
   "metadata": {},
   "source": [
    "### Generate TF Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22280142",
   "metadata": {},
   "outputs": [],
   "source": [
    " def gen_tf_spec(dataset_path):\n",
    "\n",
    "    spec_str = f\"\"\"\n",
    "    kitti_config {{\n",
    "      root_directory_path: \"{dataset_path}\"\n",
    "      image_dir_name: \"images\"\n",
    "      label_dir_name: \"labels\"\n",
    "      image_extension: \".png\"\n",
    "      partition_mode: \"random\"\n",
    "      num_partitions: 2\n",
    "      val_split: 20\n",
    "      num_shards: 10\n",
    "    }}\n",
    "    \"\"\"\n",
    "    return spec_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f982885",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(dataset_home, \"helmet_set_all\")\n",
    "record_path = os.path.join(path, \"tfrecord_spec.txt\")\n",
    "record_output = os.path.join(path, \"tfrecords/\")\n",
    "print(\"************\" + record_path)\n",
    "with open(record_path, \"w+\") as spec:\n",
    "    spec.write(gen_tf_spec(path))\n",
    "!detectnet_v2 dataset_convert -d $record_path -o $record_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cbdba7",
   "metadata": {},
   "source": [
    "### Train PeopleNet with the helmet class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38ca9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_out = os.path.join(exp_home, \"train_out\")\n",
    "train_spec_path = os.path.join(exp_home, \"train_spec.txt\")\n",
    "inf_spec_path = os.path.join(exp_home, \"inf_new_spec.txt\")\n",
    "model_out = os.path.join(exp_home, \"train_out\")\n",
    "trained_model = os.path.join(model_out, \"final_model.tlt\")\n",
    "\n",
    "os.makedirs(train_out,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43715378",
   "metadata": {},
   "outputs": [],
   "source": [
    "!detectnet_v2 train -e $train_spec_path -r $train_out -n \"final_model\" -k \"tlt_encode\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d43f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "!detectnet_v2 inference -e $inf_spec_path -i \"/datasets/helmet_set_all/images\" -o \"/tlt_exp/experiment/trained_inf_out\" -k \"tlt_encode\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b253ed7b",
   "metadata": {},
   "source": [
    "### Graph Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df122349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt   \n",
    "def get_map_data(filepath):\n",
    "    x_vals_map = []\n",
    "    y_vals_map = []\n",
    "    with open(filepath, \"r\") as f:\n",
    "        epoch = 0\n",
    "        for line in f:\n",
    "            data = eval(line)\n",
    "            if \"cur_epoch\" in data.keys():\n",
    "                epoch = data[\"cur_epoch\"]\n",
    "\n",
    "            elif \"mean average precision\" in data.keys():\n",
    "                mAP = data[\"average_precision\"][\"withhelmet\"]\n",
    "                y_vals_map.append(mAP)\n",
    "                x_vals_map.append(epoch)\n",
    "\n",
    "    return x_vals_map, y_vals_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276e78ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_file = os.path.join(train_out, \"status.json\")\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title('Helmet AP Over Epoch')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"AP %\")\n",
    "plt.ylim([0,100])\n",
    "plt.yticks(range(0,101,10))\n",
    "plt.tick_params(right=True, labelright=True)\n",
    "\n",
    "x,y = get_map_data(status_file)\n",
    "print(status_file + \"\\n max AP: \" + str(max(y)) + \" \\n\")\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
